---
layout: post
title: MLAPP-01-Introduction
---

## 1.1 什么是机器学习, 为啥要它?

> We are drowning in information and starving for knowledge. -- John Naisbitt

我们正在进入一个大数据时代. 网页上10亿; 油管视频暴涨; 人类基因丰富; 沃尔玛每秒交易量上百万, 其数据库数据量达P级($$10^15$$)之多.

大数据需要依靠机器学习来进行自动化数据分析. 具体地, 机器学习指的是, 自动地对数据进行分析, 发现规律, 并以此预测未来的数据, 或者依靠规律对未来进行决策.

本书认为, 概率论是解决此问题的最佳方案. 概率论能够在含有不确定性的问题上发挥作用. 在机器学习中, 不确定性可能是: 在以往的数据的基础上, 最佳的未来预测是什么? 对数据最佳的刻画模型是什么? 我在下一步的最佳策略是什么? 等等. 机器学习相关的概率论和统计理论关联密切, 但是在某些表述和侧重点有所不同.

我们将阐述大量的概率模型, 这些模型适用于不同的数据和任务. 同时, 我们也将阐明大量的算法用于训练和使用这些模型. 本书并非特定问题的参考答案, 而是要为读者提供一个综合的视角来研究概率模型的建模和应用. 我们同样会涉及计算效率的问题, 针对如何将方法扩展到真实的大规模数据的现实场景中, 在其它书籍中会得到更具体地阐述, 这方面书籍有(Rajaraman and Ullman 2011[^1]; Bekkerman et al. 2011[^2])

[^1]: Mining of massive datasets.
[^2]: Scaling up maching learning

值得注意的是, 大量的数据中, 其实真正有效的实际上只有很小一部分. 事实上, 很多领域的数据都具有"长尾"的现象, **长尾**体现在, 极小部分(指种类)的数据是非常常见的, 而大部分数据则是非常少见的. 例如, 谷歌每天有20%的搜索都是过去未见的. 这就意味着本书讨论的核心的关于如何从小规模数据中进行泛化的统计问题, 在大数据背景下, 仍然是非常有用的.

### 1.1.1 机器学习的类型

机器学习被分为两种, 其中一种为预测型(**predictive**)或者有监督学习(**supervised learning**). 有监督学习的目标是在给定输入$$x$$输出$$y$$对集合, $$\mathcal{D} = \{(x_i, y_i)\}_{i}^{N}$$, 学习从输入到输出的映射.