---
layout: post
title: MLAPP-01-Introduction
tag:
  - MLAPP
  - 翻译
---

## 1.1 什么是机器学习, 为啥要它?

> We are drowning in information and starving for knowledge. -- John Naisbitt

我们正在进入一个大数据时代. 网页上10亿; 油管视频暴涨; 人类基因丰富; 沃尔玛每秒交易量上百万, 其数据库数据量达P级($$10^15$$)之多.

大数据需要依靠机器学习来进行自动化数据分析. 具体地, 机器学习指的是, 自动地对数据进行分析, 发现规律, 并以此预测未来的数据, 或者依靠规律对未来进行决策.

本书认为, 概率论是解决此问题的最佳方案. 概率论能够在含有不确定性的问题上发挥作用. 在机器学习中, 不确定性可能是: 在以往的数据的基础上, 最佳的未来预测是什么? 对数据最佳的刻画模型是什么? 我在下一步的最佳策略是什么? 等等. 机器学习相关的概率论和统计理论关联密切, 但是在某些表述和侧重点有所不同.

我们将阐述大量的概率模型, 这些模型适用于不同的数据和任务. 同时, 我们也将阐明大量的算法用于训练和使用这些模型. 本书并非特定问题的参考答案, 而是要为读者提供一个综合的视角来研究概率模型的建模和应用. 我们同样会涉及计算效率的问题, 针对如何将方法扩展到真实的大规模数据的现实场景中, 在其它书籍中会得到更具体地阐述, 这方面书籍有(Rajaraman and Ullman 2011[^1]; Bekkerman et al. 2011[^2])

[^1]: Mining of massive datasets.
[^2]: Scaling up maching learning

值得注意的是, 大量的数据中, 其实真正有效的实际上只有很小一部分. 事实上, 很多领域的数据都具有"长尾"的现象, **长尾**体现在, 极小部分(指种类)的数据是非常常见的, 而大部分数据则是非常少见的. 例如, 谷歌每天有20%的搜索都是过去未见的. 这就意味着本书讨论的核心的关于如何从小规模数据中进行泛化的统计问题, 在大数据背景下, 仍然是非常有用的.

### 1.1.1 机器学习的类型

机器学习主要被分为两种, 其中一种为预测型(**predictive**)或者有监督学习(**supervised learning**). 有监督学习的目标是在给定输入$$\mathbf{x}$$输出$$y$$对集合, $$\mathcal{D} = \{(\mathbf{x}_i, y_i)\}_{i}^{N}$$, 学习从输入到输出的映射. 这个集合 $$\mathcal{D}$$称为训练集, 而 $$N$$就是样本数.

举个简单的例子, 每个样本的输入 $$\mathbf{x}_i$$ 是一个 $$D$$维的向量, 例如代表身材的身高和体重. 这个向量称为 **特征**, **属性**或者 **协变量**. 一般, 输入$$\mathcal{x}_i$$可以是复杂的数据结构对象, 例如图像, 句子, 电子邮件, 时间序列, 分子, 图等等.

类似的, 输出或者称为**响应值**可以是任何形式的数据, 但在大多数方法, $$y_i$$是一个**类别**或者属于某个有限集合的**代表**, 例如用$$y_i \in \{1, ... C\}$$ 代表男性, 女性; 或者是浮点数$$\y_i$$, 代表收入. 当 $$y_i$$ 是类别的是, 问题被称为分类, 或者是模式识别, 当 $$y_i$$ 是个浮点数时, 问题则是回归问题. 另一类问题, 被称为有序回归, 这类问题中, 输出空间 $$\mathcal{Y}$$ 有序, 想评价等级 A-F.

另一种类型的机器学习称为**描述性**或者**无监督学习**. 在这类问题中, 我们只有输入集合 $$\mathcal{D} = \{(\mathbf{x}_i\}_{i}^{N}$$, 目标是找到数据中隐含的模式. 这类问题有时候被称为**知识挖掘**(**knowledge discovery**). 目前这类问题, 缺乏全面的定义, 毕竟我们并不知道我们要寻找什么样的模式. 而且没有明确评价指标来估计误差(不想监督学习, 可以直接对比模型预测与真实的标签).

机器学习其实还有第三种, 称为**强化学习**. 该类方法主要为了解决, 在奖惩环境下如何行动. (就像婴儿学步). 虽然我们将在第5.7节中讨论决策论, 但是强化学习不在本书的讨论范围. 


![](/assets/img/MLAPP-Figure-1.1.png){:height="300px"}

## 1.2 监督学习

下面开始讨论机器学习中运用最为广泛的监督学习.

### 1.2.1 分类

本节, 我们讨论分类问题. 分类问题的目标是学习输入 $$\mathbf{x}$$ 到输出 $$y$$ 的映射, 其中 $$y\in \{1, \cdots, C\}$$, $$C$$是类别总数. 如果 $$C = 2$$ 则问题是**二分类**问题(此时 $$y\in \{0, 1\}$$); 如果 $$C > 2$$ 则问题是**多分类**问题. 如果各个类别不是互斥的(例如, 某个人可以同时被分类为高大的, 和强壮的), 此时这类问题称之为**多标签分类**问题, 但是这类问题更恰当地应当看做多个相关的二分类问题(即通常说的**多输出模型**). 当我们提到**分类问题**时, 默认多分类问题采用单个输出方式, 除非另有说明.

